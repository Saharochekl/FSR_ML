{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQL7kfyt6vsB"
      },
      "source": [
        "# Boostings: AdaBoost, GBM, XGBoost, LithtGBM, CatBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95jZVcHhD5hS"
      },
      "source": [
        "**Исполнители (ФИО):** Your answer here\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIJ-hjzVG_Lf"
      },
      "source": [
        "Здравствуйте! На прошлом семинаре вы познакомились с ансамблями - одним из методов повышения качества отдельных моделей путём объединения их в единую модель. Сегодня вы познакомитесь со вторым методом - Бустингами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7Qx_e-DCBCp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "При построении ансамблей мы обучали модели параллельно и независимо: либо одинакоые модели, каждую на случайном поднаборе данных, как в случае с Бэггингом, либо разные модели отдельно на всём наборе данных, как в случае с Блендингом. Основаня идея Бустинга: обучать модели последовательно, таким образом, чтобы кажлая следующая модель учитывала ошибки предыдущей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr8Ae9qZ5I3x"
      },
      "source": [
        "## Задача 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Первой моделью, основанной на идее последовательного обучения был AdaBoost. Эта модель послеовательно строит деревья малой высоты, зачастую высоты 1 (решающие пни), на первом шаге всем объектам даётся одинаковый вес. На каждом шаге производится классификация, затем вычисляется взвешенная ошибка текущей модели, веса правильно классифицированных объектов на следующем шаге уменьшаются, а для неправильных - увеличиваются. После этого вычисляется вес самой модели как логарифмическая функция потерь на основе ошибки модели. Итоговый ответ Бустинг вычисляет как взвешанное голосование входящих в него моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Произведите интеграцию [optuna](https://optuna.readthedocs.io/en/v2.0.0/reference/generated/optuna.integration.OptunaSearchCV.html) со sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q optuna optuna-integration[sklearn]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from optuna.integration import OptunaSearchCV\n",
        "from optuna.distributions import IntDistribution, FloatDistribution, CategoricalDistribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Загрузите датасет *LED_domain.arff*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Примените [Дерево решений](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), [Случайный лес](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) и [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) для классификации. Используйте [OptunaSearchCV](https://optuna.readthedocs.io/en/v2.0.0/reference/generated/optuna.integration.OptunaSearchCV.html) для подбора гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Изобразите кривые обучения на трейне и валидации. Сравните качество классификации итоговых моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Какая модель оказалась лучше? Есть ли эффект от бустинга? Почему?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Задача 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В оригинальной статье авторы AdaBoost используют экспоненциальную функцию потерь и оптимизируют обучение именно под неё. Однако, для других задач нам может понадобится оптимизировать различные функции потерь. Для минимизации функции используем Метод Градиентного Спуска, обучая деревья на антиградиенте. Так появился Градиентный Бустинг, позволяющий минимизировать любую дифференциируемую функцию потерь. \n",
        "\n",
        "В отличие от AdaBoost, Градиентный Бустинг ограничивает глубину деревьев не так сильно, но сохраняет идею последовательного обучения легких и простых моделей для уточнения предсказания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Используйте датасет из предыдущей задачи, примените [GBM](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) для классификации, оцените время обучения и качетсво модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Подберите гиперпараметры модели. Изобразите кривые обучения на трейне и валидации. C помощью фукнции *.staged_predict()* Изобразите изменение функции потерь и метрики в зависимости от итерации обучения на тренировочной и тестовой выборках"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Во всех деревянных алгоритмах, будь то Дерево, Лес, AdaBoost или Градиентный Бутинг на деревях, регуляризация производилась за счет простого ограничения параметров, отвечающих за рост дерева, и, как следствие, его переобучения - количество листьев, глубина и т.д.\n",
        "\n",
        "Однако, поскольку мы теперь можем оптимизировать любую функцию потерь, давайте просто добавим к ней штраф за слишком большие предсказания (соотвествует L1 и L2 регуляризации) и за большое количество листьев, и, в общем случае, можем добавлять и другие штрафы. Так и появился XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь примените [XGBoost](https://xgboost.readthedocs.io/en/stable/get_started.html) для классификации, оцените время обучения и качетсво модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Подберите гиперпараметры модели. Изобразите кривые обучения на трейне и валидации. C помощью фукнции *.predict()* и параметра *iteration_range* Изобразите функцию потерь на тренировочной и тестовой выборках"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Через несколько лет после XGBoost в Microsoft решили сделать свой аналог, который бы работал намного быстрее и эффективнее. Для этого дерево строится в высоту, так же оно штрафуется за слишком большие градиенты, выбор сплитов происходит гистограммным методом. Так появился LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь примените [LightGBM](https://lightgbm.readthedocs.io/en/stable/Python-Intro.html) для классификации, оцените время обучения и качество модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Подберите гиперпараметры модели. Изобразите кривые обучения на трейне и валидации. C помощью фукнции *.predict()* и параметров *start_iteration*, *num_iteraion*.  Изобразите функцию потерь на тренировочной и тестовой выборках"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сравните модели по качеству классификации и времени обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Какая модель оказалась лучше? Есть ли различие в их работе? Предположите, почему?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Задача 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Одним из лучших Бустингов на данный момент является CatBoost. В его основе лежат симметричные деревья: все узлы на одном уровне используют один и тот же параметр. Он был разработан для работы с категориальными данными, потому не требует их предварительной обработки, она уже зашита в него"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Загрузите датасет *richters_whole_2.csv*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Используйте [CatBoost](https://catboost.ai/docs/en/concepts/python-quickstart) для классификации, произведите подбор гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Изобразите кривые обучения на трейне и валидации. C помощью фукнции *.staged_predict()* изобразите изменение метрики качества и функции потерь на тренировочной и тестовой выборках в процессе обучения модели. Оцените качество классификации итоговой модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сравните результат с любым другим бустингом (предварительно декадируйте категориальные фичи)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Какая модель лучше справляется с категориальными данными? Предположите почему?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Задача 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "На этом классический ML заканчивается. Давайте подведём небольшой итог и пройдёмся ещё раз по тем методам, что вы теперь знаете"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сгенерируйте 3 любых двумерных датасетов для классификации, которые вы использовали в предыдущих семинарах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Проведите сравнение всех пройденных на курсе моделей классификации (включая бустинги). Подберите для них оптимальные параметры удобным вам способом, изобразите границы разделения классов с помощью [DecisionBoundaryDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.DecisionBoundaryDisplay.html) и оцените качество классификации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Какие результаты у вас получились? Прокомментируйте результаты работы ваших моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
