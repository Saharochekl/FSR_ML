{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQL7kfyt6vsB"
      },
      "source": [
        "# Ensembles: Random Forest, Bagging, Blending"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95jZVcHhD5hS"
      },
      "source": [
        "**Исполнители (ФИО):** Your answer here\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIJ-hjzVG_Lf"
      },
      "source": [
        "Здравствуйте! На прошедших семинарах мы разобрали все популярные идеи отдельных методов классического машинного обучение, однако, помимо этого есть ещё два подхода работы с этимим моделями, которые позволяют улучшить результаты в решении задач классификации и регрессии. На этом семинаре вы познакомитесь с первым из них - построение ансамблей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7Qx_e-DCBCp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Идея ансамблевого алгоритма заключается в использовании отдельных моделей для построения новой объединённой модели, основной принцип тут: Много разных моделей лучше одной. При таком подходе модели, входящие в ансамбль, начинают специализироваться на отдельных частях данных, что позволяет объединённой модели «запоминать» больше особенностей \n",
        "\n",
        "Есть два подхода построения ансамблей: \n",
        "1) Бэггинг -  объединение большого количества одинаковых моделей, каждая из которых обучается на случайной подвыборке из фичей и данных. Например, на данном принципе основан Случайный Лес (*Random Forest*), который по сути является объединением деревьев\n",
        "2) Блендинг - объединение разных моделей, каждая из которых обучается на всей тренировочной выборке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr8Ae9qZ5I3x"
      },
      "source": [
        "## Задача 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WxFjVhoHr1l"
      },
      "source": [
        "Загрузите датасет *TrafficViolation.csv*, в качестве таргета используйте колонку *Violation.Type*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAcftoIa0ldC"
      },
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Используйте [Дерево решений](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) для классификации, осуществите подбор гиперпараметров с помощью [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Постройте полученное дерево, оцените качество классификации "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Постройте [Случайный лес](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), используйте полученные параметры оптимального дерева. Оцените качество классификации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Помимо всех уже известных вам параметров Дерева решений, Случайный лес имеет параметр *n_estimators* - количество деревьев в лесе. Он также определяет склонность леса к переобучению\n",
        "\n",
        "Используйте [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), чтобы подобрать оптимальное количество деревьев в построенном вами ранее лесе. Постройте зависимость метрики качества от параметра на тренировочной и валидационной выборках с помощью атрибутов класса GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Как меняется качество классификации от количества деревьев на тренировочной и валидационной выборках? Какое оптимальное значение количества деревьев вы выбрали? Почему?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Лес, как и дерево, считает важность фичей. Выведите график важности фичей у вашего леса и постройте модель на основе важных фичей  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сравните все три модели: Дерево, Лес и Лес на важных фичах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Какая модель оказалась лучшей? Почему?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Задача 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Перебор гиперпараметров по сетке хотя и является хорошим, но не оптимальным методом подбора наилучших параметров. Поиск по сетке можно улучшить с помощью [Байесовской оптимизации](https://ru.wikipedia.org/wiki/%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2), которая позволяет проходить не по всей сетке, а на некотором оптимальном подможестве\n",
        "\n",
        "Этот подход реализован в библиотеке [optuna](https://optuna.org/), ниже приведет код использования для упрощения работы с данной либой"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q optuna\n",
        "\n",
        "from optuna import create_study\n",
        "from optuna.pruners import HyperbandPruner\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.storages import RDBStorage\n",
        "from optuna.trial import TrialState\n",
        "\n",
        "def random_forest_opt(trial):\n",
        "    # выберите диапозон рассматриваемых параметров\n",
        "    params = {\n",
        "        \"criterion\": trial.suggest_categorical(\"criterion\", ['gini', 'entropy']),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20, step=1),\n",
        "        \"random_state\": 42,\n",
        "    }\n",
        "\n",
        "    clf = RandomForestClassifier(**params)\n",
        "    clf.fit(X, y)\n",
        "\n",
        "    return clf.score(X, y)\n",
        "\n",
        "user_name = \"postgres\"\n",
        "user_password = \"postgres\"\n",
        "host = \"127.0.0.1\"\n",
        "port = \"5432\"\n",
        "database = \"gyrostab_optuna\" \n",
        "iterations = 1000 # выберите количество итераций алгоритма\n",
        "hw_iter = 0\n",
        "study_name = f\"hw_{hw_iter}\" # необобходимо менять для разных прогонов optuna\n",
        "hw_iter += 1\n",
        "\n",
        "url_str = f\"postgresql+psycopg2://{user_name}:{user_password}@{host}:{port}/{database}\"\n",
        "storage = \"sqlite:///optuna.db\"\n",
        "\n",
        "study = create_study(\n",
        "    load_if_exists=True,\n",
        "    storage=storage,\n",
        "    study_name=study_name,\n",
        "    pruner=HyperbandPruner,\n",
        "    direction=\"maximize\", # В зависимости от вашей метрики, выберите направление работы алгоритма\n",
        ")\n",
        "\n",
        "study.optimize(random_forest_opt, n_trials=iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Загрузите свой датасет из проекта"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Используйте Случайный лес для [классификации](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) и [регрессии](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) на ваших данных. Подберите гиперпараметры используя [оптуну](https://optuna.readthedocs.io/en/stable/). Изобразите кривую обучения с помощью библиотеки [plotly](https://habr.com/ru/articles/502958/), подсветите на ней точку с оптимальными гиперпараметрами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xJHj13d5Puf"
      },
      "source": [
        "## Задача 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Когда у вас уже есть какая-то хорошая модель, Бэггинг - хороший способ попробовать повысить качество, построив ансамбль на её основе. Как вы поните, его можно делать на базе любой модели, лес лишь частный случай. Обычно в Бэггинг объединяют десятки/сотни моделей, тем самым повышая шанс покрыть всю специфику данных, однако тут тоже нужно следить за переобучением "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Загрузите датасет *richters_piece_2.csv*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Используйте [Случайный лес](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) для классификации, подберите гиперпараметры, оцените качетсво"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь создайте лес самостоятельно. Для этого используйте [Бэггинг](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) для создания классификатора на основе [Дерева решений](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). Задайте параметры, аналогичные лесу выше"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сравните Случайный лес и «Мешок деревьев»"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Какой из методов оказался лучше? Предположите почему? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь выберите любой другой известный вам метод (кроме дерева и леса). Постройте [Бэггинг](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) на его оснвое. Подберите гиперпараметры у исходного метода и его Бэггинга"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сравните три полученные модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Какие модели у вас получились? Какая из них оказалась лучшей? Предположите почему?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me-QeTVU5QeL"
      },
      "source": [
        "## Задача 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь разберёмся подробнее с Блендингом. Как вы помните, в отличии от Бэггинга, Блендинг это объединение разных моделей, для каждой из них нужно производить подбор гиперпараметров, потому, Блендинг имеет смысл использовать когда у вас есть несколько обученных моделей, каждая из которых хорошо работает на какой-то части данных, например, каждая из моделей умеет идеально предсказывать один из классов, таким образом, в Блендинге модели будут дополнять друг друга"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Загрузите датасет *richters_whole_2.csv*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Есть два типа блендинга в зависимости от того, как принимается итоговое решение на основе ответов отдельных моделей. Первый это VotingClassifier, по сути взвешанное голосование: каждая модель возвращает вероятности принадлежности классам, после чего общие вероятности пренадлежности классам вычисляются как взвешенная сумма, где веса - веса моделей в Блендинге (их нужно подбирать) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Используйте две или более разных моделей классификации. Подберите гиперпараметры, оцените качество классификации, произведе диагностику моделей, используя ROC кривую"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Объедините ваши модели с помощью [VotingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html), произведите подбор весов в голосовании, оцените качество классификации и сравните с исходными моделями"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Второй вариант Блендинга это StackingClassifier: вероятности принадлежности классам от отдельных моделей идут на вход мета-модели (классификатор), которая принимает решение "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь объедините ваши модели с помощью [StackingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html), оцените качество классификации и сравните между собой варианты с разным конечным классификатором"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сравните лучший StackingClassifier с исходными моделями и VotingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Какие модели вы взяли? Какая модель оказалось лучшей? Получилось ли улучшить качество с помощью Блендинга? Предположите почему?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
