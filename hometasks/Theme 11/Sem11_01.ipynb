{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQL7kfyt6vsB"
      },
      "source": [
        "# Neural Networks: Learning Techniques and Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95jZVcHhD5hS"
      },
      "source": [
        "**Исполнители (ФИО):** Your answer here\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIJ-hjzVG_Lf"
      },
      "source": [
        "Здравствуйте, подходит к концу курс Машинного Обучения\n",
        "\n",
        "В рамках изучения нейронных сетей существует огромное количество тем и задач, однако охватить все и сразу невозможно\n",
        "\n",
        "Поэтому в этом блокноте вы познакомитесь со способами улучшения сходимости нейросетей и борьба с переобучением, а также задачей обработки естественного языка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`В данном блокноте вы будете работать с библиотекой PyTorch, для комфортной работы и чтобы не тратить время на установку, воспользуйтесь сервисом Google Collab, в котором этот инструмент уже предустановлен`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7Qx_e-DCBCp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Как улучшить сходимость нейронной сети? Казалось бы, добавим много скрытых слоев. Да, модель будет дольше учиться, зато выучит больше признаков и результат станет лучше. Однако, как вы могли заметить в предыдущем блокноте, этого не происходит. Причиной этому служит [затухание/взрыв градиента](https://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D1%80%D0%BE%D0%B1%D0%BB%D0%B5%D0%BC%D1%8B_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D1%85_%D1%81%D0%B5%D1%82%D0%B5%D0%B9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Поскольку для вычисления градиента функции потерь необходимо последовательно перемножать производные, то градиент может уменьшаться/расти экспоненциально, если множители в нашем произведении будут слишком маленькими/большими"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для решения этой проблемы существует несколько способов, которые можно сочетать:\n",
        "1. Нормализация данных\n",
        "2. Инициализация весов\n",
        "3. Нормализация выходов нейронов (Batch Normalization)\n",
        "4. Регуляризация (L1, L2, Dropout)\n",
        "\n",
        "Помимо L1, L2 регуляризации, существует так называемый Dropout подход. Суть его заключается в том, чтобы выключать(занулять) случайную долю выходов нейронов, чтобы блокировать обновление весов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr8Ae9qZ5I3x"
      },
      "source": [
        "## Задача 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Загрузите датасет *CIFAR10*\n",
        "\n",
        "Этот датасет содержит картинки размера 32 x 32 реальных объектов, представленных 10 классами: самолеты, машины, птицы, олени, кошки, собаки, лягушки, лошади, корабли и грузовики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Слой нормализации выходов нейронов представлен классом *nn.BatchNorm1d*\n",
        "\n",
        "Слой случайного выключения связей между нейронами представлен классом *nn.Dropout1d* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Опишите базовую архитектуру глубокой нейронной сети для решения задачи классификации на этом датасете. Можете использовать любые слои из *torch.nn*, кроме *BatchNorm* и *Dropout*-подобных. Добавьте по меньшей мере 7 скрытых слоев с обучаемыми параметрами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    \n",
        "    # Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Обоснуйте выбор архитектуры нейронной сети. Какие слои использовали и почему?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сделайте ещё три нейросети, в двух из которых используете по отдельности BatchNorm в каждом скрытом слое, а Dropout в нескольких последних слоях. А в третьей объедините этих два подхода"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучите все четыре нейросети решать задачу классификации картинок, по желанию используйте L1, L2 регуляризацию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сравните все 4 классификатора между собой по качеству и скорости обучения. Постройте графики обучения моделей и ROC кривые"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Улучшают ли два данных подхода качество обучения?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Задача 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ещё одним подходом для ускорения и улучшения качества обучения является [Иницализация весов](https://en.wikipedia.org/wiki/Weight_initialization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Классическая инициализация весов нормальным шумом с нулевым матожиданием и небольшой дисперсией не решает проблему затухания/взрыва градиента\n",
        "\n",
        "Условиями непоявления этой проблемы являются:\n",
        "1. Равенство дисперсий признаков на каждом слое\n",
        "2. Равенство дисперсий градиентов на каждом слое"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Из этих условий выводится инициализация весов по *Xavier* для Sigmoid - подобных функций активации, а также инициализация по *Kaiming* для ReLU - подобных функций активации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В PyTorch веса инициализируются с помощью [torch.nn.init](https://docs.pytorch.org/docs/stable/nn.init.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Пример инициализации весов\n",
        "\n",
        "activation_type = \"sigmoid\"\n",
        "init_gain = torch.nn.init.calculate_gain(activation_type)\n",
        "\n",
        "@torch.no_grad()\n",
        "def init_weights(layer):\n",
        "    if isinstance(layer, (nn.Linear, ...)): # Cписок слоев с обучаемымми параметрами\n",
        "        torch.nn.init.xavier_normal_(layer.weight, gain = init_gain) # инициализация весов\n",
        "        if layer.bias is not None:\n",
        "            torch.nn.init.zeros_(layer.bias)\n",
        "            \n",
        "model = NeuralNetwork()\n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Возьмите базовую архитектуру нейронной сети из предыдущей задачи, сделайте её неглубокой, с одинаковой функцией активации для каждого слоя и с возможностью менять эту функцию активации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Выполните эксперимент по обучению четырех нейросетей с различными функциями активации и инициализациями весов на данных из предыдущей задачи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучите нейронную сеть с функцией активации *nn.Tanh* и стандартной инициализацией весов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучите нейронную сеть с функцией активации *nn.ReLU* и стандартной инициализацией весов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучите нейронную сеть с функцией активации *nn.Tanh* и инициализацией весов по *Xavier*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучите нейронную сеть с функцией активации *nn.ReLU* и инициализацией весов по *Kaiming*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сравните все 4 классификатора между собой по качеству и скорости обучения. Постройте графики обучения моделей и ROC кривые"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Улучшает ли подход с инициализацией весов качество обучения?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Задача 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В задаче Обработки естественного языка (NLP) есть огромное количество подзадач:\n",
        "1. Эмоциональный анализ текста\n",
        "2. Машинный перевод\n",
        "3. Распознавание именованных сущностей\n",
        "4. Фильтр спама\n",
        "5. Генерация текста\n",
        "6. Распознавание речи\n",
        "7. Суммаризация\n",
        "\n",
        "и т.д."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "При этом любые текстовые данные необходимо предобработать и преобразовать в токены, то есть базовые единицы слов. Токенизацию текста можно разделить на следующие этапы:\n",
        "1. Разделение текста на слова или н-граммы\n",
        "2. Удаление пунктуационных знаков и чисел\n",
        "3. Удаление слов, имеющих слабую семантику (артикли, предлоги) - стоп-слова\n",
        "4. Извелечение токенов (корней, лемм) из слов - Стемминг или Лемматизация \n",
        "\n",
        "После токенизации текст превращают в векторное представление - *Embedding*. Его можно получать как с помощью простых моделей *BagOfWords*, так и с помощью нейросетевых методов *Word2Vec*, которые реализованы в Больших Языковых Моделях (LLM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Загрузите датасет с отзывами на фильмы с сайта [IMDb](https://www.imdb.com/) с помощью метода *datasets.load_dataset*\n",
        "\n",
        "В данном случае метка класса означает положительный отзыв или отрицательный"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -qU datasets==2.16.1\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Приведите текст к нижнему регистру и удалите знаки пунктуации и другие спецсимволы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для удобной работы c текстом существует библиотека [nltk](https://www.nltk.org/)\n",
        "\n",
        "Токенизируйте отзывы с помощью метода *nltk.tokenizer.word_tokenize*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "# загрузка токенизатора\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Удалите стоп-слова из отзывов. Для этого получите слова с помощью метода *nltk.corpus.stopwords*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# загрузка стопслов\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Лемматизируйте слова с помощью *nltk.stem.WordNetLemmatizer*, используйте *nltk.pos_tag* для определения части речи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь у нас есть лемматизированные предложения. Составьте словарь из *50* наиболее встречающихся лемм в отзывах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Превратим эти предложения в векторы с помощью меры [TF-IDF](https://ru.wikipedia.org/wiki/TF-IDF), которая показывает важность слова в документе, который является частью корпуса текстов \n",
        "\n",
        "$w_{t,d} = tf(t,d)\\cdot idf(t)$, \n",
        "\n",
        "где $w_{t,d}$ - важность слова $t$ в документе $d$, \n",
        "\n",
        "$tf(t,d)$ - частота слова $t$ в документе $d$,\n",
        "\n",
        "$idf(t)$ - логарифм отношения количества документов в корпусе к количеству документов $d$, в которых встречается слово $t$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучите любой известный вам классический или нейросетевой классификатор определять положитетельность/отрицательность отзыва на полученных векторах, являющихся репрезентацией отзывов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Возьмите готовую [BERT](https://neerc.ifmo.ru/wiki/index.php?title=BERT_(%D1%8F%D0%B7%D1%8B%D0%BA%D0%BE%D0%B2%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C))-подобную модель, из семейства [моделей](https://neptune.ai/blog/bert-and-the-transformer-architecture), которая натренирована выполнять эмоциональный анализ текста\n",
        "\n",
        "Посмотрите, как она классифицирует несколько отзывов из датасета IMDb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Пример готовой модели из модуля transformers\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\",\n",
        "                      model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "text = \"I love this movie!\"\n",
        "print(classifier(text))\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Возьмите несколько понравившихся вам фильмов разных жанров и по три различных типа отзыва к ним с сайта IMDB: положительный, смешанный, отрицательный\n",
        "\n",
        "Классифицируйте эти отзывы с помощью натренированной вами модели и с помощью готовой предтренированной модели\n",
        "\n",
        "Сравните результаты этих двух моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Совпадает ли эмоциональная оценка отзывов двумя этими моделями? Какая модель справилась лучше?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Задача 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Другой полезной и интересной задачей является генерация текста. Идея состоит в том, чтобы на основе некоторого запроса, контекста и предыдущих слов ответа сгенерировать следующее слово. Такая задача достаточно успешно решена с помощью Генеративных Предобученных Трансформеров (GPT)\n",
        "\n",
        "Отдельно про трансформеры можно говорить долго, основная статья, в которой они впервые появились [*Attention Is All You Need*](https://arxiv.org/abs/1706.03762)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Основной техникой в глубоком обучении, позволяющей решать свои задачи на основе уже существующих предобученных моделей является *Fine Tuning* (Дообучение). Идея в том, что модель уже выучила какие то представления из данных, у неё уже достаточно хорошо подобранные веса, и необходимо только немного их подкорректировать под данные нашей задачи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Загрузите модель *sberbank-ai/rugpt2-small* и токенайзер слов для неё из модуля *transformers* с помощью методов *GPT2LMHeadModel, GPT2TokenizerFast*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Найдите и загрузите понравившийся вам текст на русском языке с несколькими сотнями/тысячами предложений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Токенизируйте текст с помощью загруженного токенайзера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Дообучите GPT2 на вашем тексте с помощью класса *transformers.Trainer*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сгенерируйте несколько предложений с помощью дообученой модели и её метода *generate*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Попросите продукт [ChatGPT](https://chatgpt.com/) компании OpenAI или любую другую доступную GPT-подобную модель сгенерировать несколько предложений в стиле вашего текста. Сравните ответы двух моделей между собой"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Получились ли ответы трансформеров реалистичными? Какая модель справилась лучше с генерацией текста?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here:*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
