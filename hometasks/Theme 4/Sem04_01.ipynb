{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flwxBJKCbLVy"
      },
      "source": [
        "# Dimensionality Reduction (PCA, KernelPCA, LDA, Correlation Analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDwEEtTkr9Wn"
      },
      "source": [
        "**Исполнители (ФИО):** Your answer here\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4yiEDmKsyje"
      },
      "source": [
        "Здравствуйте! На этом семинаре вы познакомитесь с новыми методами решения задачи понижения размерности: Метод Главных Компонент (PCA) и его ядерная вариация (KernelPCA), а также примените уже известные вам методы Линейный Дискриминантный Анализ (LDA) и Корреляционный Анализ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ND0AWB6gYPOQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc6BB9hYVynC"
      },
      "source": [
        "**Полезные ссылки:**\n",
        "\n",
        "[Построение BiPlot для PCA](https://sukhbinder.wordpress.com/2015/08/05/biplot-with-python/)\n",
        "\n",
        "[Матрица частных корреляций](https://pingouin-stats.org/build/html/generated/pingouin.pcorr.html)\n",
        "\n",
        "[Графики попарных соотношений между фичами в датасете](https://seaborn.pydata.org/generated/seaborn.pairplot.html)\n",
        "\n",
        "[Сравнение PCA и Kernel PCA](https://scikit-learn.org/stable/auto_examples/decomposition/plot_kernel_pca.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXOJOfxPZbW2"
      },
      "source": [
        "## Задача 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSzelsuJZguL"
      },
      "source": [
        "В этой задаче вам предстоит сравнить два классических подхода для уменьшения размерности - Наивный Корреляционный Анализ и Метод Главных Компонент (PCA)\n",
        "\n",
        "Загрузите датасет с [ирисами](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cVNaPQIjcBdm"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umSeyGAscBIY"
      },
      "source": [
        "Как вы помните из курса АнДана, если в модели есть зависимые параметры, мы можем попробовать убрать один из них, тем самым понизив размерность, однако это работает не всегда. Используя матрицу корреляций, попробуйте понизить размерность данных. Если возможно, визуализируйте полученные данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xMA6z-06dfZH"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmWA7IjQdf85"
      },
      "source": [
        "**Вопрос:** Какие фичи убрали и почему?\n",
        "\n",
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJW4W8g4d0RL"
      },
      "source": [
        "Не наивный подход для уменьшения размерности заключается в построении нового базиса на основе данных таким образом, чтобы максимизировать «информацию» базисных векторов на каждом шаге построения\n",
        "\n",
        "Одним из таких вариантов построения является Метод Главных Компонент (PCA), который сохраняет вариацию в данных. Этот метод также позволяет посмотреть долю объясненной дисперсии векторов нового базиса, чтобы оценить, сколько «информации» сохранилось\n",
        "\n",
        "Теперь попробуйте понизить размерность данных с помощью [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). Если возможно, визуализируйте полученные данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NWiEJibwkMSp"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4R68gZ_kPoA"
      },
      "source": [
        "**Вопрос:** Сколько векторов нового базиса вы взяли для уменьшения размерности? Как много информации вы потеряли?\n",
        "\n",
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVpCzEd-lALP"
      },
      "source": [
        "Теперь сравните качество классификации Логистической регрессии на трех полученных датасетах: исходный и два варианта понижения размерности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uKuJTL_VlYDU"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF76Q_PolYlx"
      },
      "source": [
        "**Вопрос:** Как понижение размерности повлияло на качество классификации? Как вы думаете, почему?\n",
        "\n",
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiLHS6IzutCI"
      },
      "source": [
        "## Задача 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HYNqUT65jZb"
      },
      "source": [
        "Для визуализации данных строят график в пространстве 2-х главных компонент. При этом можно использовать так называемый BiPlot, позволяющий получить больше информации, чем просто двумерный\n",
        "график. BiPlot, помимо того, что отображает проекции данных в пространстве новых фичей на две главные компоненты, также добавляет проекции векторов исходных фичей, что позволяет увидеть их вклад в главные компоненты (оси координат в BiPlot)\n",
        "\n",
        "Визуализируйте [BiPlot](https://sukhbinder.wordpress.com/2015/08/05/biplot-with-python/) на данных из предыдущей задачи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_CTYuBb944ic"
      },
      "outputs": [],
      "source": [
        "# Youre code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEIupMTf8aDC"
      },
      "source": [
        "**Вопрос:** Опишите вклад исходных фичей в две главные компоненты\n",
        "\n",
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et5Esop78j0n"
      },
      "source": [
        "Теперь загрузите датасет о диабете [load_diabets](https://scikit-learn.org/1.7/modules/generated/sklearn.datasets.load_diabetes.html). Примените к нему понижение размерности и постройте BiPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "huIGl49n9-ud"
      },
      "outputs": [],
      "source": [
        "# Youre code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2TC53Oe9_i5"
      },
      "source": [
        "BiPlot может быть полезен, чтобы сделать некоторые предроложения о взаимосвязи исходых параметрами и классов. Например, угол между исходными параметрами в первом приближении отражает степень их зависимости, а направление вектора может говорить о том, что точки, лежащие близ него имеют большее значение по данному параметру. Однако, так как на BiPlot мы работаем с проекцией только на две компоненты, эти соотношения могут выполняться не всегда.\n",
        "\n",
        "Проверьте, выполняются ли какие-либо соотношения для каких-то параметров в вашем случае."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wUfaYIkrFusm"
      },
      "outputs": [],
      "source": [
        "# Youre code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olKaiuuIFusn"
      },
      "source": [
        "**Вопрос:** Получилось ли извлечь какую-то дополнительную информацию из BiPlot? Если да, то какую?\n",
        "\n",
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxpdA5M_5fB2"
      },
      "source": [
        "## Задача 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYRa_MDcFusn"
      },
      "source": [
        "Помимо классического PCA есть и другие способы понижать размерность. Для начала давайте рассмотрим уже известный вам Линейный дискриминантный анализ (LDA), он позволяет не только решать задачу классификации, но и понижать размерность.\n",
        "\n",
        "Как вы помните из лекции, LDA максимизирует межклассовую вариацию и минимизирует внутриклассовую вариацию, то есть последовательно строит базис такой, чтобы на каждом шаге направление вдоль базисного вектора максимизировало «расстояние» между классами.\n",
        "\n",
        "\n",
        "Загрузите датасет dim032.txt и попробуйте понизить размерность с помощью [LDA](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UMkwja_wFusn"
      },
      "outputs": [],
      "source": [
        "# Youre code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o88tdB4mFusn"
      },
      "source": [
        "**Вопрос:** Сколько векторов получилось в новом базисе, какие из них вы взяли и почему?\n",
        "\n",
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhlOT3NDFusn"
      },
      "source": [
        "Как вы помните из прошлого семинара, в случае сложной топологии данных, бывает полезно применить ядро, которое позволяет нам перейти в новое пространство, в котором данные становястя ближе к линейно разделимым. Аналогично для PCA есть его ядерная модификация - [Kernel PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html). Однако так как мы совершали переход в новое пространство, для Ядерного PCA BiPlot построить не получится."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вопрос:** Как вы думаете, почему не получится построить BiPlot для Kernel PCA?\n",
        "\n",
        "Your answer here"
      ],
      "metadata": {
        "id": "9l6BEXtExPNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь попробуйте применить Ядерный PCA с нелинейным ядром, чтобы понизить размерность"
      ],
      "metadata": {
        "id": "7C3NKzXXxPoT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "U-RlJiDPFuso"
      },
      "outputs": [],
      "source": [
        "# Youre code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsWcNf0gFuso"
      },
      "source": [
        "**Вопрос:** Сколько векторов получилось в новом базисе, какие из них вы взяли и почему?\n",
        "\n",
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yHRZPFjFuso"
      },
      "source": [
        "Теперь сравните качество классификации Логистической регрессии на всех полученных датасетах: исходный и с понижением размерности (PCA, Kernel PCA, LDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "H-p8mGYKFuso"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj_QN86YFuso"
      },
      "source": [
        "**Вопрос:** Как понижение размерности повлияло на качество классификации? Какой вариант понижения размерности оказался наиболее эффективен? Как вы думаете, почему?\n",
        "\n",
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UATWm2uUv6K5"
      },
      "source": [
        "## Задача 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP-CH5TQv7s4"
      },
      "source": [
        "Загрузите набор данных [lfw_people](https://scikit-learn.org/1.7/modules/generated/sklearn.datasets.fetch_lfw_people.html#) с параметрами min_faces_per_person = 100 и resize = 0.1\n",
        "1. Попробуйте понизить размерность датасета так, чтобы его можно было отрисовать\n",
        "2. Попробуйте объединить несколько подходов понижения размерности данных\n",
        "3. Попробуйте добиться наилучшего соотношения между количеством фичей и качеством классификации, обоснуйте свой выбор\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2m7IHxOz45mt"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}